<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Interactive Voice Interview</title>
  <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
  <style>
    body { font-family: Arial, sans-serif; padding: 20px; max-width: 800px; margin: 0 auto; }
    #statusPanel { background: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
    #log { border: 1px solid #ddd; padding: 15px; border-radius: 5px; min-height: 200px; }
    .status { color: #3498db; margin: 5px 0; }
    .error { color: #e74c3c; }
    .question { color: #0f9d58; font-weight: bold; }
    .answer { color: #4285f4; margin-left: 20px; }
    button {
      padding: 10px 20px; margin: 5px;
      background: #4285f4; color: white;
      border: none; border-radius: 4px;
      cursor: pointer;
    }
    button:disabled { background: #9e9e9e; cursor: not-allowed; }
  </style>
</head>
<body>
  <h1>Interactive Voice Interview</h1>
  <div id="statusPanel">
    <div id="micStatus">Microphone: Not accessed</div>
    <div id="recogStatus">Speech Recognition: Not initialized</div>
  </div>
  <button id="initBtn">Initialize System</button>
  <button id="startBtn" disabled>Start Interview</button>
  <button id="stopBtn" disabled>Stop Interview</button>
  <div id="log"></div>

  <script>
    let recognition;
    let currentQuestionIndex = 0;
    const questions = [
      "What is the caller's name?",
      "What is the phone number?",
      "What is the pet's name?",
      "How old is the pet?",
      "What service is requested?",
      "What is the specific reason for the call?",
      "What is the preferred appointment time?",
      "Which doctor is requested?",
      "Who handled this call?",
      "Is a follow-up needed?",
      "Any remarks?",
      "Is this a new or existing client?",
      "What is the pet's type or breed?",
      "Where did the caller hear about us?",
      "Is the appointment confirmed?",
      "What is the urgency level?",
      "Is a callback scheduled?",
      "Any additional instructions?"
    ];
    let answers = [];
    let isRecognitionRunning = false;
    let isInterviewRunning = false;
    let currentAnswer = "";

    const initBtn = document.getElementById("initBtn");
    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const micStatus = document.getElementById("micStatus");
    const recogStatus = document.getElementById("recogStatus");
    const logDiv = document.getElementById("log");

    // Log messages
    function logMessage(msg, className = "status") {
      const div = document.createElement("div");
      div.className = className;
      div.textContent = msg;
      logDiv.appendChild(div);
      logDiv.scrollTop = logDiv.scrollHeight;
    }

    function logError(msg) {
      logMessage(msg, "error");
    }

    // Speak function
    function speakText(text, callback) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';
      utterance.onend = callback;
      window.speechSynthesis.speak(utterance);
    }

    // Initialize system
    initBtn.addEventListener("click", async () => {
      try {
        logMessage("Initializing system...");
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop());
        micStatus.textContent = "Microphone: Access granted";
        micStatus.style.color = "#0f9d58";

        recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = "en-US";

        recognition.onstart = () => {
          recogStatus.textContent = "Speech Recognition: Active";
          isRecognitionRunning = true;
        };

        recognition.onend = () => {
          recogStatus.textContent = "Speech Recognition: Ready";
          isRecognitionRunning = false;
          
          if (isInterviewRunning && currentAnswer) {
            logMessage(`Answer: ${currentAnswer}`, "answer");
            answers.push(currentAnswer); // Store the answer
            currentAnswer = "";
            askNextQuestion();
          }
        };

        recognition.onresult = (e) => {
          currentAnswer = e.results[0][0].transcript.trim();
          recognition.stop();
        };

        recognition.onerror = (e) => {
          logError(`Recognition error: ${e.error}`);
          isRecognitionRunning = false;
          if (e.error === 'no-speech') {
            logMessage("No speech detected. Please try again.");
            recognition.start();
          }
        };

        recogStatus.textContent = "Speech Recognition: Ready";
        recogStatus.style.color = "#0f9d58";
        startBtn.disabled = false;
        initBtn.disabled = true;
        logMessage("System ready. Click 'Start Interview' to begin.");
      } catch (err) {
        logError(`Initialization failed: ${err.message}`);
        micStatus.textContent = "Microphone: Access denied";
        micStatus.style.color = "#db4437";
      }
    });

    // Start the interview
    startBtn.addEventListener("click", () => {
      if (!isInterviewRunning) {
        isInterviewRunning = true;
        currentQuestionIndex = 0;
        logMessage("Interview started...", "status");
        startBtn.disabled = true;
        stopBtn.disabled = false;
        answers = []; // Clear previous answers
        askNextQuestion();
      }
    });

    // Stop the interview
    stopBtn.addEventListener("click", () => {
      isInterviewRunning = false;
      if (isRecognitionRunning) {
        recognition.stop();
      }
      logMessage("Interview stopped by user.", "status");
      startBtn.disabled = false;
      stopBtn.disabled = true;
    });

    // Ask the next question
    function askNextQuestion() {
      if (currentQuestionIndex < questions.length) {
        const question = questions[currentQuestionIndex];
        logMessage(`Question ${currentQuestionIndex + 1}: ${question}`, "question");
        
        speakText(question, () => {
          if (!isRecognitionRunning) {
            recognition.start();
          }
        });
        
        currentQuestionIndex++;
      } else {
        isInterviewRunning = false;
        logMessage("Interview completed. Thank you!", "status");
        speakText("Thank you for completing the interview!", () => {
          startBtn.disabled = false;
          stopBtn.disabled = true;
          logAnswersToGoogleSheets(answers); // Submit answers to Google Sheets
        });
      }
    }

    // Submit answers to Google Sheets
    async function logAnswersToGoogleSheets(answers) {
      try {
        const response = await fetch("https://call-logger-server.onrender.com/logAnswers", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({ answers }),
        });

        if (response.ok) {
          const message = await response.text();
          logMessage(message, "status");
        } else {
          const error = await response.text();
          logError(error);
        }
      } catch (error) {
        logError("Failed to log answers into Google Sheets: " + error.message);
      }
    }
  </script>
</body>
</html>